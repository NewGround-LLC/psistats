Experiments plan
===================================

1. Selecting optimal K svd
===================================
k = 50, [512,256], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 82.85%
      age : 79.06%
political : 64.31%
      ope : 38.08%
      con : 22.83%
      ext : 23.87%
      agr : 21.20%
      neu : 26.09%
------------------
     Mean : 44.79%
      Std : 26.39%
Evaluation MSE: 2.75, MAE: 0.93
Test Data Eval:
Prediction accuracies:
   gender : 92.60%
      age : 85.03%
political : 66.66%
      ope : 44.76%
      con : 24.33%
      ext : 30.86%
      agr : 24.83%
      neu : 32.17%
------------------
     Mean : 50.15%
      Std : 27.58%
Evaluation MSE: 2.00, MAE: 0.83
Step 50000: train loss = 2.62, test loss = 1.93 (duration: 0.0193648338317871)
Learning rate start: 0.0001, dropout = 0.50, input_features = 50, layers = [512,256]
Mean train/test errors: 3.7237 / 2.6983, train optimizer: train/Adam
===================================

k = 128, [512,256], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 82.55%
      age : 84.35%
political : 64.09%
      ope : 38.76%
      con : 24.04%
      ext : 29.14%
      agr : 21.62%
      neu : 29.37%
------------------
     Mean : 46.74%
      Std : 26.24%
Evaluation MSE: 2.26, MAE: 0.89
Test Data Eval:
Prediction accuracies:
   gender : 92.14%
      age : 82.97%
political : 67.34%
      ope : 47.56%
      con : 25.79%
      ext : 32.35%
      agr : 25.66%
      neu : 33.01%
------------------
     Mean : 50.85%
      Std : 26.57%
Evaluation MSE: 2.20, MAE: 0.85
Step 50000: train loss = 2.15, test loss = 1.95 (duration: 0.0256168842315674)
Learning rate start: 0.0001, dropout = 0.50, input_features = 128, layers = [512,256]
Mean train/test errors: 3.3249 / 2.7468, train optimizer: train/Adam
===================================

k = 256, [512,256], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 84.52%
      age : 90.50%
political : 65.56%
      ope : 42.08%
      con : 27.69%
      ext : 31.37%
      agr : 26.98%
      neu : 34.94%
------------------
     Mean : 50.46%
      Std : 26.01%
Evaluation MSE: 1.63, MAE: 0.83
Test Data Eval:
Prediction accuracies:
   gender : 92.53%
      age : 80.67%
political : 67.06%
      ope : 47.68%
      con : 25.68%
      ext : 34.35%
      agr : 26.48%
      neu : 35.94%
------------------
     Mean : 51.30%
      Std : 25.69%
Evaluation MSE: 2.44, MAE: 0.86
Step 50000: train loss = 1.19, test loss = 2.11 (duration: 0.0329899787902832)
Learning rate start: 0.0001, dropout = 0.50, input_features = 256, layers = [512,256]
Mean train/test errors: 2.7575 / 2.8115, train optimizer: train/Adam
===================================

k = 512, [512,256], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 83.35%
      age : 93.29%
political : 67.11%
      ope : 45.68%
      con : 31.77%
      ext : 38.60%
      agr : 33.53%
      neu : 40.27%
------------------
     Mean : 54.20%
      Std : 23.86%
Evaluation MSE: 1.30, MAE: 0.78
Test Data Eval:
Prediction accuracies:
   gender : 91.29%
      age : 81.45%
political : 67.35%
      ope : 47.95%
      con : 25.18%
      ext : 29.27%
      agr : 24.62%
      neu : 33.04%
------------------
     Mean : 50.02%
      Std : 26.66%
Evaluation MSE: 2.34, MAE: 0.86
Step 50000: train loss = 1.23, test loss = 1.93 (duration: 0.0508708953857422)
Learning rate start: 0.0001, dropout = 0.50, input_features = 512, layers = [512,256]
Mean train/test errors: 2.4148 / 2.7665, train optimizer: train/Adam
===================================

k = 512, [1024,512], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 91.42%
      age : 96.35%
political : 72.76%
      ope : 67.32%
      con : 58.38%
      ext : 65.72%
      agr : 62.25%
      neu : 67.17%
------------------
     Mean : 72.67%
      Std : 13.80%
Evaluation MSE: 0.80, MAE: 0.63
Test Data Eval:
Prediction accuracies:
   gender : 93.61%
      age : 81.45%
political : 67.26%
      ope : 46.39%
      con : 27.74%
      ext : 28.16%
      agr : 21.65%
      neu : 28.50%
------------------
     Mean : 49.34%
      Std : 27.87%
Evaluation MSE: 2.34, MAE: 0.85
Step 50000: train loss = 0.78, test loss = 1.80 (duration: 0.104606866836548)
Dropout probability = 0.50, input_features = 512, layers = [1024,512], network type: dnn, batch size: 100
Learning rate initial: 0.0001, [annealing step = 10000, decay rate = 0.96]
Mean train/test errors: 1.5634 / 2.6367, train optimizer: train/Adam

++++++++++++++++++++++++++++++++++++++++++
k = 1024
++++++++++++++++++++++++++++++++++++++++++
===================================

k = 1024, [1024,512], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 91.91%
      age : 96.53%
political : 75.78%
      ope : 76.92%
      con : 70.34%
      ext : 75.92%
      agr : 74.94%
      neu : 76.19%
------------------
     Mean : 79.82% <—— !!!!!
      Std : 9.20%
Evaluation MSE: 0.69, MAE: 0.57 <—— !!!!!
Test Data Eval:
Prediction accuracies:
   gender : 93.74%
      age : 84.23%
political : 65.18%
      ope : 45.56%
      con : 28.19%
      ext : 27.83%
      agr : 20.94%
      neu : 28.92%
------------------
     Mean : 49.32%
      Std : 28.25%
Evaluation MSE: 2.10, MAE: 0.83
Step 50000: train loss = 0.68, test loss = 1.88 (duration: 0.156962871551514)
Learning rate start: 0.0001, dropout = 0.50, input_features = 1024, layers = [1024,512]
Mean train/test errors: 1.3947 / 2.4864, train optimizer: train/Adam
===================================

k = 1024, [1536,512], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 93.76%
      age : 96.78%
political : 78.40%
      ope : 81.54%
      con : 79.01%
      ext : 80.50%
      agr : 80.13%
      neu : 80.89%
------------------
     Mean : 83.88% <—— !!!!!
      Std : 7.15%
Evaluation MSE: 0.61, MAE: 0.53 <—— !!!!!
Test Data Eval:
Prediction accuracies:
   gender : 93.89%
      age : 83.93%
political : 64.35%
      ope : 45.07%
      con : 28.05%
      ext : 28.84%
      agr : 22.01%
      neu : 28.63%
------------------
     Mean : 49.35%
      Std : 27.97%
Evaluation MSE: 2.13, MAE: 0.84
Step 50000: train loss = 0.51, test loss = 2.04 (duration: 0.183140993118286)
Learning rate start: 0.0001, dropout = 0.50, input_features = 1024, layers = [1536,512]
Mean train/test errors: 1.2370 / 2.4423, train optimizer: train/Adam
===================================

k = 1024, [2048,1024], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 95.69%
      age : 97.51%
political : 81.56%
      ope : 83.56%
      con : 82.19%
      ext : 82.59%
      agr : 82.54%
      neu : 82.96%
------------------
     Mean : 86.07% <—— !!!!!
      Std : 6.54%
Evaluation MSE: 0.51, MAE: 0.49 <—— !!!!!
Test Data Eval:
Prediction accuracies:
   gender : 95.68%
      age : 82.53%
political : 65.06%
      ope : 40.61%
      con : 24.67%
      ext : 26.53%
      agr : 29.90%
      neu : 30.83%
------------------
     Mean : 49.48%
      Std : 27.83%
Evaluation MSE: 2.31, MAE: 0.85
Step 30000: train loss = 0.50, test loss = 1.97 (duration: 0.25626802444458)
Learning rate start: 0.0001, dropout = 0.50, input_features = 1024, layers = [2048,1024]
Mean train/test errors: 1.1413 / 2.4997, train optimizer: train/Adam
===================================

k = 1024, [2048,1024], lr = 10e-5
————
Training Data Eval:
Prediction accuracies:
   gender : 87.10%
      age : 93.91%
political : 65.32%
      ope : 44.18%
      con : 29.54%
      ext : 34.59%
      agr : 27.99%
      neu : 34.14%
------------------
     Mean : 52.10%
      Std : 26.54%
Evaluation MSE: 1.25, MAE: 0.77
Test Data Eval:
Prediction accuracies:
   gender : 93.76%
      age : 79.85%
political : 66.50%
      ope : 47.78%
      con : 28.53%
      ext : 33.25%
      agr : 28.10%
      neu : 34.75%
------------------
     Mean : 51.56%
      Std : 25.40%
Evaluation MSE: 2.49, MAE: 0.89
Step 30000: train loss = 1.36, test loss = 2.35 (duration: 0.263324975967407)
Learning rate start: 1e-05, dropout = 0.50, input_features = 1024, layers = [2048,1024]
Mean train/test errors: 3.6571 / 3.9365, train optimizer: train/Adam
===================================

k = 1024, [2048,1024], lr = 10e-3 !!!!
————
Training Data Eval:
Prediction accuracies:
   gender : 90.88%
      age : 96.57%
political : 76.73%
      ope : 80.77%
      con : 79.97%
      ext : 80.60%
      agr : 80.17%
      neu : 80.85%
------------------
     Mean : 83.32% <—— !!!!!
      Std : 6.73%
Evaluation MSE: 0.65, MAE: 0.52 <—— !!!!!
Test Data Eval:
Prediction accuracies:
   gender : 92.17%
      age : 82.53%
political : 63.88%
      ope : 40.88%
      con : 22.65%
      ext : 21.98%
      agr : 25.69%
      neu : 31.96%
------------------
     Mean : 47.72%
      Std : 28.08%
Evaluation MSE: 2.64, MAE: 0.87
Step 30000: train loss = 0.66, test loss = 1.53 (duration: 0.286546945571899)
Learning rate start: 0.001, dropout = 0.50, input_features = 1024, layers = [2048,1024]
Mean train/test errors: 1.0069 / 2.5757, train optimizer: train/Adam
===================================

k = 1024, [2048,1024], lr = 10e-4, decay rate = 0.60
————
Training Data Eval:
Prediction accuracies:
   gender : 92.88%
      age : 96.85%
political : 72.55%
      ope : 65.04%
      con : 57.25%
      ext : 64.08%
      agr : 59.52%
      neu : 65.56%
------------------
     Mean : 71.72%
      Std : 15.02%
Evaluation MSE: 0.77, MAE: 0.63
Test Data Eval:
Prediction accuracies:
   gender : 95.53%
      age : 81.44%
political : 66.17%
      ope : 45.94%
      con : 26.91%
      ext : 30.05%
      agr : 26.49%
      neu : 29.94%
------------------
     Mean : 50.31%
      Std : 27.32%
Evaluation MSE: 2.37, MAE: 0.87
Step 30000: train loss = 0.71, test loss = 1.98 (duration: 0.330607175827026)
Dropout probability = 0.50, input_features = 1024, layers = [2048,1024]
Learning rate initial: 0.0001, [annealing step = 5000, decay rate = 0.60]
Mean train/test errors: 1.2427 / 2.5231, train optimizer: train/Adam

++++++++++++++++++++++++++++++++++++++++++
k = 256
++++++++++++++++++++++++++++++++++++++++++
k = 256, [512,256], lr = 10e-3
————
Training Data Eval:
Prediction accuracies:
   gender : 80.38%
      age : 94.70%
political : 64.35%
      ope : 45.76%
      con : 33.19%
      ext : 38.77%
      agr : 33.75%
      neu : 42.65%
------------------
     Mean : 54.19%
      Std : 23.08%
Evaluation MSE: 1.16, MAE: 0.75
Test Data Eval:
Prediction accuracies:
   gender : 90.89%
      age : 79.60%
political : 67.33%
      ope : 44.73%
      con : 21.41%
      ext : 24.62%
      agr : 17.27%
      neu : 27.72%
------------------
     Mean : 46.70%
      Std : 28.83%
Evaluation MSE: 2.54, MAE: 0.87
Step 30000: train loss = 1.23, test loss = 1.67 (duration: 0.0294990539550781)
Dropout probability = 0.50, input_features = 256, layers = [512,256]
Learning rate initial: 0.001, [annealing step = 10000, decay rate = 0.96]
Mean train/test errors: 1.7812 / 2.4980, train optimizer: train/Adam
===================================
k = 256, [512,256], lr = 10e-5
————
Training Data Eval:
Prediction accuracies:
   gender : 65.77%
      age : 69.78%
political : 53.33%
      ope : 18.22%
      con : 9.26%
      ext : 9.01%
      agr : 5.49%
      neu : 10.60%
------------------
     Mean : 30.18%
      Std : 27.75%
Evaluation MSE: 3.95, MAE: 1.07
Test Data Eval:
Prediction accuracies:
   gender : 84.83%
      age : 76.10%
political : 55.38%
      ope : 37.93%
      con : 17.13%
      ext : 25.79%
      agr : 15.64%
      neu : 26.83%
------------------
     Mean : 42.45% <——— ! Not fully converged? Do need to try more iterations?
      Std : 26.72%
Evaluation MSE: 2.87, MAE: 0.95
Step 30000: train loss = 4.63, test loss = 2.43 (duration: 0.0314240455627441)
Dropout probability = 0.50, input_features = 256, layers = [512,256]
Learning rate initial: 1e-05, [annealing step = 10000, decay rate = 0.96]
Mean train/test errors: 10.3114 / 8.1123, train optimizer: train/Adam
===================================
k = 256, [512,256], lr = 10e-5
————
Training Data Eval:
Prediction accuracies:
   gender : 69.05%
      age : 72.69%
political : 56.38%
      ope : 24.59%
      con : 14.04%
      ext : 12.52%
      agr : 9.80%
      neu : 14.90%
------------------
     Mean : 34.25%
      Std : 27.06%
Evaluation MSE: 3.53, MAE: 1.03
Test Data Eval:
Prediction accuracies:
   gender : 82.75%
      age : 79.44%
political : 59.69%
      ope : 39.48%
      con : 22.86%
      ext : 24.07%
      agr : 16.34%
      neu : 28.53%
------------------
     Mean : 44.14%
      Std : 26.39%
Evaluation MSE: 2.56, MAE: 0.91
Step 50000: train loss = 2.80, test loss = 2.50 (duration: 0.0326149463653564)
Dropout probability = 0.50, input_features = 256, layers = [512,256]
Learning rate initial: 1e-05, [annealing step = 10000, decay rate = 0.96]
Mean train/test errors: 7.6990 / 6.0011, train optimizer: train/Adam
===================================
k = 256, [512,256], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 83.28%
      age : 90.75%
political : 65.47%
      ope : 41.07%
      con : 26.13%
      ext : 31.54%
      agr : 26.15%
      neu : 33.88%
------------------
     Mean : 49.78%
      Std : 26.26%
Evaluation MSE: 1.63, MAE: 0.83
Test Data Eval:
Prediction accuracies:
   gender : 92.49%
      age : 81.30%
political : 66.60%
      ope : 46.04%
      con : 24.08%
      ext : 31.93%
      agr : 23.90%
      neu : 31.90%
------------------
     Mean : 49.78%
      Std : 26.95%
Evaluation MSE: 2.40, MAE: 0.87
Step 50000: train loss = 1.51, test loss = 2.18 (duration: 0.0325100421905518)
Dropout probability = 0.50, input_features = 256, layers = [512,256]
Learning rate initial: 0.0001, [annealing step = 10000, decay rate = 0.96]
Mean train/test errors: 2.7683 / 2.8228, train optimizer: train/Adam