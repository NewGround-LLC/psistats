Experiments plan
===================================

1. Selecting optimal K svd
===================================
k = 50, [512,256], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 82.85%
      age : 79.06%
political : 64.31%
      ope : 38.08%
      con : 22.83%
      ext : 23.87%
      agr : 21.20%
      neu : 26.09%
------------------
     Mean : 44.79%
      Std : 26.39%
Evaluation MSE: 2.75, MAE: 0.93
Test Data Eval:
Prediction accuracies:
   gender : 92.60%
      age : 85.03%
political : 66.66%
      ope : 44.76%
      con : 24.33%
      ext : 30.86%
      agr : 24.83%
      neu : 32.17%
------------------
     Mean : 50.15%
      Std : 27.58%
Evaluation MSE: 2.00, MAE: 0.83
Step 50000: train loss = 2.62, test loss = 1.93 (duration: 0.0193648338317871)
Learning rate start: 0.0001, dropout = 0.50, input_features = 50, layers = [512,256]
Mean train/test errors: 3.7237 / 2.6983, train optimizer: train/Adam
===================================

k = 128, [512,256], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 82.55%
      age : 84.35%
political : 64.09%
      ope : 38.76%
      con : 24.04%
      ext : 29.14%
      agr : 21.62%
      neu : 29.37%
------------------
     Mean : 46.74%
      Std : 26.24%
Evaluation MSE: 2.26, MAE: 0.89
Test Data Eval:
Prediction accuracies:
   gender : 92.14%
      age : 82.97%
political : 67.34%
      ope : 47.56%
      con : 25.79%
      ext : 32.35%
      agr : 25.66%
      neu : 33.01%
------------------
     Mean : 50.85%
      Std : 26.57%
Evaluation MSE: 2.20, MAE: 0.85
Step 50000: train loss = 2.15, test loss = 1.95 (duration: 0.0256168842315674)
Learning rate start: 0.0001, dropout = 0.50, input_features = 128, layers = [512,256]
Mean train/test errors: 3.3249 / 2.7468, train optimizer: train/Adam
===================================

k = 256, [512,256], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 84.52%
      age : 90.50%
political : 65.56%
      ope : 42.08%
      con : 27.69%
      ext : 31.37%
      agr : 26.98%
      neu : 34.94%
------------------
     Mean : 50.46%
      Std : 26.01%
Evaluation MSE: 1.63, MAE: 0.83
Test Data Eval:
Prediction accuracies:
   gender : 92.53%
      age : 80.67%
political : 67.06%
      ope : 47.68%
      con : 25.68%
      ext : 34.35%
      agr : 26.48%
      neu : 35.94%
------------------
     Mean : 51.30%
      Std : 25.69%
Evaluation MSE: 2.44, MAE: 0.86
Step 50000: train loss = 1.19, test loss = 2.11 (duration: 0.0329899787902832)
Learning rate start: 0.0001, dropout = 0.50, input_features = 256, layers = [512,256]
Mean train/test errors: 2.7575 / 2.8115, train optimizer: train/Adam
===================================

k = 512, [512,256], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 83.35%
      age : 93.29%
political : 67.11%
      ope : 45.68%
      con : 31.77%
      ext : 38.60%
      agr : 33.53%
      neu : 40.27%
------------------
     Mean : 54.20%
      Std : 23.86%
Evaluation MSE: 1.30, MAE: 0.78
Test Data Eval:
Prediction accuracies:
   gender : 91.29%
      age : 81.45%
political : 67.35%
      ope : 47.95%
      con : 25.18%
      ext : 29.27%
      agr : 24.62%
      neu : 33.04%
------------------
     Mean : 50.02%
      Std : 26.66%
Evaluation MSE: 2.34, MAE: 0.86
Step 50000: train loss = 1.23, test loss = 1.93 (duration: 0.0508708953857422)
Learning rate start: 0.0001, dropout = 0.50, input_features = 512, layers = [512,256]
Mean train/test errors: 2.4148 / 2.7665, train optimizer: train/Adam
===================================

k = 1024, [1024,512], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 91.91%
      age : 96.53%
political : 75.78%
      ope : 76.92%
      con : 70.34%
      ext : 75.92%
      agr : 74.94%
      neu : 76.19%
------------------
     Mean : 79.82% <—— !!!!!
      Std : 9.20%
Evaluation MSE: 0.69, MAE: 0.57 <—— !!!!!
Test Data Eval:
Prediction accuracies:
   gender : 93.74%
      age : 84.23%
political : 65.18%
      ope : 45.56%
      con : 28.19%
      ext : 27.83%
      agr : 20.94%
      neu : 28.92%
------------------
     Mean : 49.32%
      Std : 28.25%
Evaluation MSE: 2.10, MAE: 0.83
Step 50000: train loss = 0.68, test loss = 1.88 (duration: 0.156962871551514)
Learning rate start: 0.0001, dropout = 0.50, input_features = 1024, layers = [1024,512]
Mean train/test errors: 1.3947 / 2.4864, train optimizer: train/Adam
===================================

k = 1024, [1536,512], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 93.76%
      age : 96.78%
political : 78.40%
      ope : 81.54%
      con : 79.01%
      ext : 80.50%
      agr : 80.13%
      neu : 80.89%
------------------
     Mean : 83.88% <—— !!!!!
      Std : 7.15%
Evaluation MSE: 0.61, MAE: 0.53 <—— !!!!!
Test Data Eval:
Prediction accuracies:
   gender : 93.89%
      age : 83.93%
political : 64.35%
      ope : 45.07%
      con : 28.05%
      ext : 28.84%
      agr : 22.01%
      neu : 28.63%
------------------
     Mean : 49.35%
      Std : 27.97%
Evaluation MSE: 2.13, MAE: 0.84
Step 50000: train loss = 0.51, test loss = 2.04 (duration: 0.183140993118286)
Learning rate start: 0.0001, dropout = 0.50, input_features = 1024, layers = [1536,512]
Mean train/test errors: 1.2370 / 2.4423, train optimizer: train/Adam
===================================

k = 1024, [2048,1024], lr = 10e-4
————
Training Data Eval:
Prediction accuracies:
   gender : 95.69%
      age : 97.51%
political : 81.56%
      ope : 83.56%
      con : 82.19%
      ext : 82.59%
      agr : 82.54%
      neu : 82.96%
------------------
     Mean : 86.07% <—— !!!!!
      Std : 6.54%
Evaluation MSE: 0.51, MAE: 0.49 <—— !!!!!
Test Data Eval:
Prediction accuracies:
   gender : 95.68%
      age : 82.53%
political : 65.06%
      ope : 40.61%
      con : 24.67%
      ext : 26.53%
      agr : 29.90%
      neu : 30.83%
------------------
     Mean : 49.48%
      Std : 27.83%
Evaluation MSE: 2.31, MAE: 0.85
Step 30000: train loss = 0.50, test loss = 1.97 (duration: 0.25626802444458)
Learning rate start: 0.0001, dropout = 0.50, input_features = 1024, layers = [2048,1024]
Mean train/test errors: 1.1413 / 2.4997, train optimizer: train/Adam
===================================

k = 1024, [2048,1024], lr = 10e-5
————
Training Data Eval:
Prediction accuracies:
   gender : 87.10%
      age : 93.91%
political : 65.32%
      ope : 44.18%
      con : 29.54%
      ext : 34.59%
      agr : 27.99%
      neu : 34.14%
------------------
     Mean : 52.10%
      Std : 26.54%
Evaluation MSE: 1.25, MAE: 0.77
Test Data Eval:
Prediction accuracies:
   gender : 93.76%
      age : 79.85%
political : 66.50%
      ope : 47.78%
      con : 28.53%
      ext : 33.25%
      agr : 28.10%
      neu : 34.75%
------------------
     Mean : 51.56%
      Std : 25.40%
Evaluation MSE: 2.49, MAE: 0.89
Step 30000: train loss = 1.36, test loss = 2.35 (duration: 0.263324975967407)
Learning rate start: 1e-05, dropout = 0.50, input_features = 1024, layers = [2048,1024]
Mean train/test errors: 3.6571 / 3.9365, train optimizer: train/Adam
===================================

k = 1024, [2048,1024], lr = 10e-3 !!!!
————
Training Data Eval:
Prediction accuracies:
   gender : 90.88%
      age : 96.57%
political : 76.73%
      ope : 80.77%
      con : 79.97%
      ext : 80.60%
      agr : 80.17%
      neu : 80.85%
------------------
     Mean : 83.32%
      Std : 6.73%
Evaluation MSE: 0.65, MAE: 0.52
Test Data Eval:
Prediction accuracies:
   gender : 92.17%
      age : 82.53%
political : 63.88%
      ope : 40.88%
      con : 22.65%
      ext : 21.98%
      agr : 25.69%
      neu : 31.96%
------------------
     Mean : 47.72%
      Std : 28.08%
Evaluation MSE: 2.64, MAE: 0.87
Step 30000: train loss = 0.66, test loss = 1.53 (duration: 0.286546945571899)
Learning rate start: 0.001, dropout = 0.50, input_features = 1024, layers = [2048,1024]
Mean train/test errors: 1.0069 / 2.5757, train optimizer: train/Adam